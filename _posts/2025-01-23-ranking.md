---
layout: post
title: "Algorithmic ranking is unfairly maligned"
image: /img/ranking/sunset.jpg
tags: 
description: Only some kinds are bad
excerpt: 
permalink: /ranking/
background_color: rgb(169,156,114)
category: "rants"
#seo:
# date_modified: 2025-01-23
#last_modified_at: 2025-01-23
comment:
  lemmy: "https://old.lemmy.world/post/24628104"
#  substack: "https://dynomight.substack.com/p/ranking/"

---

What does "algorithmic ranking" bring to mind for you? Personally, I get visions of political ragebait and supplement hucksters and unnecessary cleavage. I see cratering attention spans and groups of friends on the subway all blankly swiping at glowing rectangles. I see overconfident charlatans and the hollow eyes eyes of someone reviewing 83 photo she just made her boyfriend take of her in front of a sunset. Most of all, I see dreams of creative expression perverted into a desperate scramble to do whatever it takes to please the Algorithm.

Of course, lots of people like algorithmic ranking, too.

[!["I like how it shows me cool stuff"](/img/ranking/coffee.png)](http://hyperboleandahalf.blogspot.com/2013/05/depression-part-two.html)

I theorize that the skeptics are right and algorithmic ranking is in fact bad. But it's not algorithmic ranking *per se* that's bad—it's just that the algorithms you're used to don't care about your goals. That might be an inevitable consequence of ["enshittification"](https://en.wikipedia.org/wiki/Enshittification), but the solution isn't to avoid all algorithms, but just to avoid algorithms you can't *control*. This will become increasingly important in the future as algorithmic ranking becomes algorithmic everything.

## Why algorithmic ranking is bad for some people sometimes

You've heard it all before. I think algorithmic ranking leads many people to spend time and emotional energy on things they'd rather not spend them on. I also think it leads lots of people to believe preposterous bullshit promoted by charismatic charlatans. I'm disturbed when I see how kids interact with addictive algorithms, but then I notice that adults are much the same. You know the story.

A common defense of algorithmic ranking is that "your feed is your problem". If you're getting political ragebait and unnecessary cleavage, then that's on you for engaging with that stuff. If you *actually* cared about the things you *pretend* you care about, everything would be fine. The problem is looking you in the mirror.

I find this defense bewildering and almost hostile. I mean, where is it spelled out *how* you're supposed to behave to get the content you want? Maybe there are little like buttons, but what do they do? How do they interact with all the other signals, like what you watch? It's unclear.

Now, I'm sure that many of the people who complain about ragebait and cleavage are in fact drawn to them in some way. Maybe they don't swipe away fast enough when that stuff is inserted into their endless content trough. If they only had eyes for philosophy lectures and meditation videos, maybe that's all they'd see.

OK, but so what? Where's the empathy? *Everyone* has some divergence between the urges they feel and the urges they wish they felt. We don't judge alcoholics who throw away their booze. We don't make fun of gambling addicts who avoid travel to Vegas or Monaco. So why is it wrong to not want lurid but unhealthy content dangled in front of you?

One of the fundamental arts of being a human is using your "better self" to try to control your "lesser self". You can put a giant calendar on your wall to track when you exercise. You can keep junk food out of your home. You can write your algorithmic ranking manifestos using an app that permanently deletes everything if you stop typing for 5 seconds. These tricks are good. We need more of them! Algorithmic ranking—as we know it—is the opposite.

So what would I propose instead? How about... sliders? Why can't I click a slider to say "more educational content" or "less political rage" or "no David Sinclair-esque supplement huckster bullshit"?

Or how about an algorithm that just does what it says on the tin? Remember, YouTicBooX might let you "like" stuff, but the algorithm's *goal* isn't to show you stuff you'd like. The goal is to make money. Your likes are just another feature to be integrated with the rest of your behavioral profile for increasing engagement and targeting ads, thank you very much. The algorithm is running *on* you, not *for* you.

## But what about the market?

Another common defense of current algorithms goes like this: If they're so bad, then why did they win? If people *wanted* sliders, they would have picked services with sliders. But they didn't. Go make SliderTube if you want. No one cares. There isn't some pent-up demand for algorithms that give more control to our better selves.

Sometimes people also gesture at the [tyranny of the marginal user](https://nothinghuman.substack.com/p/the-tyranny-of-the-marginal-user). The idea is that, sure, power users like control. But where companies really compete is in the fight for the "marginal user", the person who is *almost* ready to quit. This person only vaguely understands what a phone is, has never heard of "algorithms", likes flashing lights, and has the attention span of a pissed-off chimpanzee. They will not tolerate any complexity, so all sliders must go. Sorry, power users.

There's clearly *something* to these arguments. But still: If your portal to the world is designed for the marginal user, surely you've gone wrong *somewhere*, no?

## What happened to Netflix?

In the long-long ago, Netflix had star ratings. You'd rate stuff between 1 and 5 stars and get a sorted list of predictions:

| Chunking Express                                | 4.49   |
| Days of Being Wild                              | 4.51   |
| Solaris                                         | 4.57   |
| In the Mood for Love                            | 4.62   |
| Master and Commander: The Far Side of the World | 4.98   |

Nowadays, you get a disorienting set of categories like DARK COMEDIES ABOUT ITALIAN FEUDALISM and LIFE IS SHORT—WATCH IT AGAIN and THINGS YOU'RE IN THE MIDDLE OF, HELPFULLY PLACED IN A INCONSISTENT LOCATION. Instead of star ratings, there are "match percentages", but you have to interact to see them and they always seem to be 98%.

What happened? Well, the story is in the public record. (See, for example [this post](https://askgib.substack.com/p/a-brief-history-of-netflix-personalization) and [this post](https://askgib.substack.com/p/a-brief-history-of-netflix-personalization-31d) by Gibson Biddle.) In short, Netflix realized a bunch of things:

1. That they needed to concentrate everything on increasing subscriber revenue. And that the main goal of recommendations should be subscriber *retention*, or making sure people don't cancel.

2. That the things people rate highly aren't always the same as what they actually *watch*. It's cool that you gave [*The Seventh Seal*](https://en.wikipedia.org/wiki/The_Seventh_Seal) five stars. But after a long day at work and finally getting the kids to bed, are you really going to choose [*Andrei Rublev*](https://en.wikipedia.org/wiki/Andrei_Rublev_(film)) over *The Great British Bachelorette and the Furious 7*?

3. That to retain people, you need to get them started watching new stuff. Lots of people want to watch *Friends*, so Netflix will pay $100 million/year for *Friends*. But if you just join, binge every episode of *Friends*, and then cancel, that's bad. However, if the *Friends* button were to—say—randomly shift around in the interface, maybe while hunting for it you'll get hooked on some other (hopefully cheaper) shows and stick around longer.

4. That beyond your explicit ratings, there are lots of implicit signals like what you watch, what you click on, what devices you use, and how long you stop scrolling when shown different kinds of thumbnails. These implicit signals are more useful than explicit rankings when predicting what to show you to keep you subscribed.

5. That many people don't want to rate stuff. And (I speculate) that this provides a convenient excuse to drop the whole star rating system and replace it with the "whatever the hell order we want" system that prevails today, where the match % means nothing and promises nothing.

Netflix could have kept the star ratings as some kind of optional feature for the nerds, hidden away in some dusty submenu. But they didn't. They 100% killed the star ratings for everyone. Why? I guess maintaining features takes work. But mostly I think they figured that most star rating diehard wouldn't actually quit the platform. They'd grumble but accept the new system and thereby be Retained. And probably they were right.

Now, I don't mean to vilify Netflix. Sure, it's an amoral automaton doing whatever maximizes profits. But this is hardly the worst example of algorithmic ranking, and hey, this is capitalism! If Netflix tried to be "principled" and stuck with star ratings, maybe some other company would have displaced them? Don't hate the player, hate the game? (Maybe don't hate the game either?)

## What algorithmic ranking should be

Let me summarize my argument so far:

1. Algorithmic ranking *as we know it* is designed to maximize money for the companies doing the ranking, duh.

2. That's great if what you want is to be addicted or—more precisely—if your behavior happens to create incentives for rankings that are well-aligned with your goals in life. Otherwise, it's not.

3. Companies settled on these algorithms for a reason. It's not because they're evil, it's because this is what's profitable.

If you accept all that, then what follows?

One view is that this is further proof we must smash capitalism and end the malign power of the invisible hand. That's intellectually coherent, but not my style.

Another view is that, well, this is the outcome of the market. It's pointless to fight the equilibrium, so we should just live with the algorithms. This is also not my style.

A third view is that we must reject algorithmic ranking. Refuse to use any social media with algorithmic ranking. Subscribe to blogs using [RSS](https://dynomight.net/feed.xml). Install browser extensions that block YouTube's recommendations. Chronological timelines only. Human curation only, forever.

This third view *is* very much my style. One of the reasons I love blogging is that I can reach people without worrying about the damn algorithms. (Hi.) But I've come to believe it's a dead end. After all, people *like* algorithmic ranking. Maybe with better interfaces or a bigger social movement, more people would shift towards human curation. But I suspect not that many, and the arc of history bends towards algorithms.

And *good* algorithmic ranking—which you *control*—would be awesome.

I mean, I appreciate that people subscribe to this blog. But I find it a little disturbing that if someone less well-known than me wrote the same thing, then many fewer people would read it. (I find it *extremely* disturbing that if someone more famous wrote it, then many more people would read it.) Yet that's an inevitable consequence of relying on subscriptions instead of algorithms.

This isn't (only) an issue of vanity. I think it leads to an "invisible graveyard" of contributions that never happen. Say you're a sane person who doesn't want to spend hours every week writing for strangers on the internet. But maybe you're—I don't know—maybe you're on the board of your local volunteer fire department. And maybe you have one sizzling banger to write about how local volunteer fire department boards should be organized. That information is important! Reality is fractally complex! But probably you won't write it, because almost none of the people who'd benefit from it will ever see it.

I think the solution is to embrace algorithmic ranking, but insist on "control"—to insist that the algorithm serves your goals and not someone else's.

How could that happen? In principle, we could all just refuse to use services without control. But I'm skeptical this would work, because of rug-pulls. The same forces that made TikTok into TikTok will still exist and history is filled with companies providing control early on, getting a dominant position, and then taking the control away. Theoretically everyone could leave at that point, but that rarely seems to happen in practice.

Instead, I think the control needs to be somehow "baked in" from the beginning. There needs to be some kind of technological/legal/social structures in place that makes rug pulls impossible.

What exactly should those structures be? And what *exactly* is "control", after all? I don't know! Those seem like difficult technical problems. But they don't seem *that* hard, do they? I suspect the main reason they haven't been solved is that we haven't tried very hard. We should do that.

And—I dare say—we should do it quickly. My guess is that algorithmic *ranking* will soon become a sort of all-encompassing algorithmic *interface*. More about that soon, but if all the information that enters your brain is being filtered by an algorithm, it seems important that you know the algorithm is on your side.

*Thanks*: [Steve Newman](https://amistrongeryet.substack.com/), [Séb Krier](https://x.com/sebkrier)

