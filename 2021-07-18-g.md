---
layout: post
title: "Physical tests, mental tests, and factor analysis as a cigar"
image: /img/g/cigar.jpg
tags: statistics personality
hero_light: false
dark_title: false
background_color: black
description: "What heritability really is: A fluid statistic that changes whenever society changes."
permalink: /g/
background_color: rgb(60,64,50)
head: "<style>
video{
  display: block;
  margin: 0 auto;
}
details{
    padding: 0pt;
    margin-bottom: 10pt;
    border-left: none;
    }
details summary{
  padding-bottom: 0pt;
  padding: 5pt;
  padding-left: 15pt;
  cursor: pointer;
}
img{
    display:block;
    margin-left: auto;
    margin-right: auto;
    max-height: 250pt;
}
table{
  display:block;
  }
table tr{
    border-style: hidden;
    text-align:left;
}
@media (min-width:501px){
table{
  margin-left: 15pt;
  max-width:100;
  max-width:100%;
  font-size: 90%;
}
}
@media (max-width:500px) and (min-width:301px) {
table{
  max-width:100;
  max-width:100%;
  font-size: 3.2vw;
}
}
@media (max-width:300px) {
table{
  max-width:100;
  max-width:100%;
  font-size: 0.5em;
}
.fixed{
    max-width:100;
    max-width:100%;
    overflow:scroll;
}
}
</style>
<script type=\"text/x-mathjax-config\"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: \"none\" } } }); </script>
       <script type=\"text/x-mathjax-config\">
         MathJax.Hub.Config({
           tex2jax: {
             inlineMath: [ ['$','$']],
             processEscapes: true
           }
         });
       </script>
       <script src=\"https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\" type=\"text/javascript\"></script>
"
---

Is there a general factor of intelligence?

This question is a trap. If you try to answer it, you'll find yourself beset by semantic questions. What's *intelligence*? What's a *factor*?

But say those questions don't derail you. You then enter a bleak valley of statistical arcana. Are the eigenvalues consistent with a factor analysis model? Do they imply a causal relationship?

This is all backwards. If your goal is to understand the external world, you can skip the handwringing and start by looking at the damn data.

Let's do that. The facts are pretty simple. People who are good at one physical task also tend to be good at running. Faster runners tend to be able to do more push-ups. For mental tasks, the same positive correlations exist: People who are good at arithmetic reasoning also tend to have good sequential memories.

Still, do these correlations have some deeper meaning? One theory is that you can model people's performance on all mental tasks using just a single number plus random noise. This is the idea behind the method called factor analysis, which is often described in technical ways. However, as I'll explain, it all really boils down to the question of how much the data looks like a cigar.

{% comment %}
### Contents
{:.no_toc}

<div style="font-size:100%;" markdown="1">
* auto-gen TOC:
{:toc}
</div>
{% endcomment %}

## Physical tests are correlated

To start, let's forget about intelligence, and ask an easier question: Does it make sense to refer to some people as "more physically fit" than others? I found three studies that gave people a bunch of different physical tests and make enough data available to re-analyze.

Paper | Population
- | - 
[Baumgartner and Zuidema, 1972](https://doi.org/10.1080/10671188.1972.10615157) | 283 male and 336 female college students in Michigan
[Marsh and Redmaye, 1994](https://doi.org/10.1123/jsep.16.1.43) | 105 students at two private girls' schools in Sydney
[Ibrahim et al., 2011]((https://doi.org/10.2466/03.06.19.25.pms.113.5.491-508)) | 330 Malaysian students aged 12-15

Are strong people also fast? Here's the correlations among men in Baumgartner and Zuidema's study. Women are similar except with lower correlations in upper-body strength.

[![baumgartner 1973 physical fitness correlations](/img/g/tables/baumgartner1972.svg)](/img/g/tables/baumgartner1972.pdf)

And here are the other studies (click to open/close):

{% comment %}
<details markdown="1">
<summary><b>Baumgartner and Zuidema</b></summary>
[![baumgartner 1973 physical fitness correlations](/img/g/tables/baumgartner1972.svg)](/img/g/tables/baumgartner1972.pdf)
(This is males, with tests grouped by color. Females are similar, except with lower correlations in upper-body strength.)
</details>
{% endcomment %}

<details markdown="1">
<summary><b>Marsh and Redmaye</b></summary>
[![marsh 1994 physical fitness correlations](/img/g/tables/marsh1994.svg)](/img/g/tables/marsh1994.pdf)
</details>

<details markdown="1">
<summary><b>Ibrahim et al.</b></summary>
[![ibrahim 2011 physical fitness correlations](/img/g/tables/ibrahim2011.svg)](/img/g/tables/ibrahim2011.pdf)
</details>

Is this surprising? Perhaps not. But it gives a useful point of comparison.

## Mental tests are correlated

We can do the same thing with mental tests. I found four relevant studies.

Paper | Population
- | - 
[Alderton et al. 1997](https://doi.org/10.1207/s15327876mp0901_1) | 12,813 members of the US Navy, Army and Air Forces
[Deary, 2000](https://doi.org/10.1093/acprof:oso/9780198524175.001.0001) |  365 representative Scottish people
[Chabris 2011](http://www.chabris.com/Chabris2007a.pdf) | 111 Boston adults 18 - 60 years old
[MacCann et al., 2014](https://doi.org/10.1037/a0034755) | 688 students from colleges around the US.

Alderton et al. use a test battery designed to measure aptitude for various military tasks. Some of these, like tracking and target identification, are partly physical. Here are the results.

[![alderton 1997 correlations](/img/g/tables/alderton1997.svg)](/img/g/tables/alderton1997.pdf)

And here are the other three studies (click to open/close):

<details markdown="1">
<summary><b>Deary</b></summary>
[![chabris 2007 correlations](/img/g/tables/chabris2007a.svg)](/img/g/tables/chabris2007a.pdf)
These subjects were tested on the 11-component revised [Wechsler Adult Intelligence Scale](https://en.wikipedia.org/wiki/Wechsler_Adult_Intelligence_Scale#WAIS-R).

<span style="font-size:80%;">Incidentally, the origins of these data are somewhat obscure: Chabris published them, crediting [Deary (2000)](https://doi.org/10.1093/acprof:oso/9780198524175.001.0001) who in turn credits personal communication from Crawford, with no other information. Whoever Crawford is, they deserve more recognition on [Wikipedia](https://en.wikipedia.org/wiki/G_factor_(psychometrics)#Cognitive_ability_testing).</span>

</details>

<details markdown="1">
<summary><b>Chabris</b></summary>
[![chabris 2007 correlations](/img/g/tables/chabris2007b.svg)](/img/g/tables/chabris2007b.pdf)
The data was gathered as part of a project to test decision-making. [Raven's matrices](https://en.wikipedia.org/wiki/Raven%27s_Progressive_Matrices) test shape pattern recognition, working memory is tested via [3-back](https://en.wikipedia.org/wiki/N-back), and the coordinate encoding tests check if people can tell the distance or orientation of a dot relative to a line.
</details>

<details markdown="1">
<summary><b>MacCann et al.</b></summary>
[![maccann 2014 correlations](/img/g/tables/maccann2014.svg)](/img/g/tables/maccann2014.pdf)
The colors group the tests into those that test fluid reasoning, comprehension, quantitative knowledge, visual processing, and long-term storage/retrieval.
</details>

## What do we see?

The same overall pattern holds for both physical and mental tests.

First, **almost everything is positively correlated**. You might imagine that people with more upper-body strength would be worse runners, what with the extra muscle they need to carry around. You might imagine that people who are good at paragraph comprehension would be worse at math. But that's not what happens.

Second, **more similar stuff is more correlated**. It's natural that chin-ups are strongly correlated with pull-ups, or that arithmetic reasoning is strongly correlated with mathematics knowledge. It's more surprising that hand-grip strength is correlated with the 75-yd dash or that paragraph comprehension is correlated with target identification, but these correlations are weaker.

Third, **the results are robust**. The tests span several decades, different countries, and many different test batteries. The basic pattern doesn't change.

So, things are correlated[^diversity-and-corrs]. No one seems to seriously dispute this. So why all the controversy?

[^diversity-and-corrs]: The mental correlations are somewhat stronger than the physical ones, but I don't take that too seriously. Correlation strengths depend on the population being measured. Imagine doing physical tests on a group of 20 year olds. If you throw in a bunch of 80 year olds, they'll be be worse at everything and correlations will skyrocket. The mental tests above looked at more diverse populations than the physical tests.

For one thing, the discussion sometimes ascends into meta-controversy. Bored arguing if "general intelligence" exists? Argue about the definition. That doesn't excite you? Argue about [if there is anything controversial](https://doi.org/10.1007/s10519-014-9646-x).

On the lower planes of argument, the main issue of contention is if the tests are *just correlated* or if there's something deeper happening. One way to approach this is to ask, how many numbers would do you need to describe someone? Suppose you've tested people on four physical tasks:

* Push-ups
* Pull-ups
* 5 kilometer run
* 100 meter sprint

With four numbers for each person, you could describe everyone perfectly. With *zero* numbers, the best you could do is remember the population averages. The question is, can you get a good approximation with just a single number? This is the basic idea behind the statistical technique called [factor analysis](https://en.wikipedia.org/wiki/Factor_analysis).

## Factor analysis is like a cigar

While factor analysis is usually described with fancy technical language, the basic idea is simple: Picture your data as a point-cloud, approximate it with a cigar, and then describe each point using its position along the length of the cigar. If a cigar fits the data well, then one number captures all the interesting latent structure behind the data. If it doesn't fit well, then there's something more interesting going on.

Let's make this concrete. Say you go out and grab random people and test them, and get this data:

{% comment %}
```
Person    Test 1   Test 2   Test 3
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Antonio    1       -1        1.5
Bart      -0.5      0.5     -0.75
Cathy     -2        2       -3
Dara        .67     -.67     1
```
{% endcomment %}

<div style="display:flex; justify-content:center;" markdown="1">
<div markdown="1">

Person | Test 1 | Test 2 | Test 3
-|-|-|-
Antonio |    1    |   -1   |     1.5
Bart    |    .67  |   -.67 |    1
Cathy   |  -0.5   |   0.5  |   -0.75
Dara    |  -2     |   2    |   -3

</div>
</div>

<br>

You can visualize the data as a magical rotating point-cloud:

<!--
![spinning point cloud of dataset](/img/g/3dplot/data.gif)
-->

{% include video.html where="/img/g/3dplot/data" title="spinning point cloud of dataset" %}

This data is special: The points fall along a straight line. This means you can represent each person using a single number (their position on the line).

### Simulations
{:.no_toc}

Now, say you wanted to simulate some fake testing data. A simple way would be to find some fixed direction of variation, and then randomly generate random points along it. Formally, let **w** be a vector that's the direction of variation. To generate a person (i.e., a set of test scores), draw a random number **g** from a standard [Normal distribution](https://en.wikipedia.org/wiki/Normal_distribution) and then multiply it with the direction of variation.

Since we have three tests, you need three numbers to specify a direction. Suppose you use the direction **w = (1, -1, 1.5)**. You'd get a dataset that looks like this:

<!--
![factor analysis with no noise](/img/g/3dplot/line.gif)
-->

{% include video.html where="/img/g/3dplot/line" title="factor analysis with no noise" %}

Of course, real data will never look like that---there will always be "noise". To account for this, let's update our simulator, by adding some random noise to each point. This produces data that look like a cigar.

<!--
![factor analysis with noise](/img/g/3dplot/cigar.gif)
-->

{% include video.html where="/img/g/3dplot/cigar-nolines" title="factor analysis with noise" %}


The critical thing here is that cigars are rotationally symmetric. If you "roll" the point cloud along the main axis of variation, it will still look very similar.

OK. We can't put it off any longer. What's this "factor analysis" thing? It's an algorithm[^factor-analysis] that takes a real dataset and adjusts the shape of the cigar so that the simulated data will look as much like the real data as possible. It can modify the direction of variation, and how "thick" the cigar is, but that's it.

[^factor-analysis]: All this describes the *simplest possible* variant of factor analysis, which is all we need here, and also all I know how to explain without getting into Eigendecompositions and whatnot.


If your dataset looks like a cigar, factor analysis will fit well. If not, it will fit poorly. Here's an example of the kind of data factor analysis can't represent:

<!--
![cigar](/img/g/3dplot/noncigar.gif)
-->

{% include video.html where="/img/g/3dplot/noncigar-nolines" title="data that factor analysis doesn't fit" %}

### The meaning of cigars
{:.no_toc}

Factor analysis tries to approximate your data with a cigar. Why should you care about this?

Let's back up. As we saw earlier, data on physical or mental tests is correlated. If you learn that Bob scored well on *paragraph comprehension* that raises your estimate for how Bob will do on *coding speed*.

But say your data was a cigar. Take Bob's position along the length of the cigar, and call it **g**. Let's imagine that Bob's value for **g** is low. If that's all you know, and you had to guess Bob's coding speed, you'd give a low guess.

Now, suppose that in addition to **g**, you learn that Bob did well on paragraph comprehension. How does this change your estimate of Bob's coding speed? Amazingly, *it doesn't*, at all. The single number **g** contains all the shared information between the tests.

In a cigar distribution, once you know **g**, everything else is just random noise--one test no longer tells you anything about any other. (Mathematically, once you control for **g**, the partial correlations of the tests are zero.)

In a *non*-cigar distribution, this doesn't happen. There's no single number that will make all the test uncorrelated. There's interesting structure would remain unexplained.

## Mental tests aren't not cigars

What does real data look like? Is it a cigar? Can we capture all the structure with a single number?

We'll need to talk about the "shape" of data quantitatively. For any dataset, you can find a set of lines that represent the shape[^svd]. For example, here's the earlier cigar data:

[^svd]: I don't know how to give a non-technical explanation of how to find these lines, so here a technical one. You can compute them for any dataset by doing a [singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition) of the covariance matrix of the data.

{% include video.html where="/img/g/3dplot/cigar" title="factor analysis with noise and singular vectors" %}

This plot alternates between just showing the simulated data and showing the lines that represent the shape of the data. In this case, the blue line corresponds to the main direction of variation, while the shorter red and green lines correspond to the random noise added to each point. Since factor analysis models are rotationally symmetric, you can see that the shorter lines are the same length.

In contrast, here's the earlier "non-cigar" data:

{% include video.html where="/img/g/3dplot/noncigar" title="data that factor analysis doesn't fit with singular vectors" %}

Here, the shorter green and red lines are different lengths, reflecting that there is no rotational symmetry.

{% comment %}
cut this?
{% endcomment %}

So here's our plan: Take real datasets, compute these lines, and see how long they are.

I'd like to show you the real data from the datasets above, but none of them seem to be publicly available. Still, we can approximate it by generating data from a multivariate Normal with the known covariance. Here's the first three tests of Alderton et al.'s (Paragraph comprehension, work knowledge, and general science).

<!--

![chabris's data](/img/g/3dplot/chabris.mp4)

-->

{% include video.html where="/img/g/3dplot/alderton" %}

It's not a perfect cigar, but it's not exactly *not* a cigar either. Here are the relative lengths of the three directions:

```
1st direction:   0.890
2nd direction:   0.362
3rd direction:   0.279
```





What if we use all seven tests? We can't make pretty pictures in seven dimensions, but we can still do the math. With **N** tests, a factor analysis model always produces **1** "long" direction and **N-1** "short" directions. These short directions should have the same length. If we plot the length of the directions, it should look like this:

![exact factor analysis lengths](/img/g/tables/factor analysis model_svds.svg)

Is that what the lengths on real data look like? Well, judge for yourself. Here are the results for Alderton et al.:

[![alderton factor analysis lengths](/img/g/tables/alderton1997_svds.svg)](/img/g/tables/alderton1997_svds.pdf)

And here are the results for the other mental tests: (Click to open/close)

<details markdown="1">
<summary><b>Deary</b></summary>
[![Deary physical fitness factor analysis lengths](/img/g/tables/chabris2007a_svds.svg)](/img/g/tables/chabris2007a_svds.pdf)
</details>

<details markdown="1">
<summary><b>Chabris</b></summary>
[![Chabris physical fitness factor analysis lengths](/img/g/tables/chabris2007b_svds.svg)](/img/g/tables/chabris2007b_svds.pdf)
</details>

<details markdown="1">
<summary><b>MacCann et al.</b></summary>
[![MacCann physical fitness factor analysis lengths](/img/g/tables/maccann2014_svds.svg)](/img/g/tables/maccann2014_svds.pdf)
</details>

{% comment %}

Physical tests look similar, or perhaps slightly worse:

<center>

<details markdown="1">
<summary><b>Baumgartner and Zuidema</b></summary>
[![baumgartner 1973 physical fitness factor analysis lengths](/img/g/tables/baumgartner1972_svds.svg)](/img/g/tables/baumgartner1972_svds.pdf)
</details>

<details markdown="1">
<summary><b>Marsh and Redmaye</b></summary>
[![Marsh and Redmaye 1994 physical fitness factor analysis lengths](/img/g/tables/marsh1994_svds.svg)](/img/g/tables/marsh1994_svds.pdf)
</details>

<details markdown="1">
<summary><b>Ibrahim et al.</b></summary>
[![Ibrahim et al. 2011 physical fitness factor analysis lengths](/img/g/tables/ibrahim2011_svds.svg)](/img/g/tables/ibrahim2011_svds.pdf)
</details>

</center>

{% endcomment %}

Do these look exactly like what factor analysis can produce? No. But it's a reasonable approximation.

**Note: How do you compute g? Give details of g for each dataset**

Here's another way of visualizing things. For each dataset, we can compute the *partial* correlations, i.e., the correlations once you control for **g**. Here's what that gives for Alderton et al.:

[![alderton 1997 correlations](/img/g/tables/alderton1997_partials.svg)](/img/g/tables/alderton1997_partials.pdf)

And here's the partial correlations for the other studies:

<details markdown="1">
<summary><b>Deary</b></summary>
[![chabris 2007 partial correlations](/img/g/tables/chabris2007a_partials.svg)](/img/g/tables/chabris2007a_partials.pdf)
</details>

<details markdown="1">
<summary><b>Chabris</b></summary>
[![chabris 2007 partial correlations](/img/g/tables/chabris2007b_partials.svg)](/img/g/tables/chabris2007b_partials.pdf)
</details>

<details markdown="1">
<summary><b>MacCann et al.</b></summary>
[![maccann 2014 partial correlations](/img/g/tables/maccann2014_partials.svg)](/img/g/tables/maccann2014_partials.pdf)
</details>

If factor analysis was a perfect fit, these would all be zero, which they aren't. But they aren't all that large either.

## What would *g* look like?

Factor analysis is a decent but not perfect model of mental tests. What does this tell us about how intelligence works? Well, suppose that factor analysis was a *perfect* model. Would that mean that we're all born with some single number *g*, and this determines how well we do on these tests?

No. A perfect fit would only mean that, across a population, a single number would *describe* how people do on tests (except for the "noise"). It does not mean that there's a single number or switch that *causes* test performance to be correlated.

This is a point that comes up in Cosma Shalizi's popular essay [*g*, a Statistical Myth](http://bactra.org/weblog/523.html). I think this essay is correct, but widely misinterpreted, likely because the *myth* that's being refuted isn't explicitly stated. Few people notice that this essay contains no real data. (Go check if you don't believe me.) That's fine, because the primary argument of this essay is that even if a factor analysis model *did* fit, that there could still be multiple independent events causing the correlations.

<!--
That's fine, but it's still strange to see this essay cited so often as the final word on *g* given that it doesn't actually engage with the external world.
-->

Shalizi emphasizes that even though the tests are correlated, it's possible that there are many *independent causes* that produce them. I'd go further---we *know* there are many causes. While intelligence is strongly [heritable](/heritability), it's highly polygenic. [Dozens of genes](https://doi.org/10.1038/ng.3869) are already known to be linked to it, and more are likely to be discovered. It's harder to quantify environmental influences, but there are surely many that matter there, too.

So, is there a magical number *g* somewhere in our brains that determines how good we are at thinking? No, just like there's no single number that says how good we are at running or balancing. That doesn't change the empirical fact that a single number provides a good *summary* of how good we are at various mental tasks.

{% comment %}
Here's an analogy: What determines how quickly an air purifier can clean the air? Lots of things: The quality of the filters, the number of filters, the strength of the fan, etc. Yet, if you tell me the [clean-air delivery rate](https://en.wikipedia.org/wiki/Clean_air_delivery_rate), that's all I need to know to predict how it will work. There's lots of *causes*, but they can be summarized by a single number.

{% endcomment %}


### Footnotes
{:.no_toc}

<p style="font-size:50%">

